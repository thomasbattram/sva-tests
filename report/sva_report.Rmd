# Assessing the best practice for surrogate variable analysis in epigenome-wide association studies

```{r setoptions, eval = TRUE, echo = FALSE}
opts_chunk$set(echo = FALSE, 
            warning = FALSE, 
            message = FALSE, 
            cache = FALSE, 
            dpi = 300)
```

```{r call_source}
read_chunk("~/sva_tests/report/sva_report.R")
```

``` {r load_data, results = "hide", message = FALSE, warning = FALSE}
```

```{r timings_setup, results = "hide", message = FALSE, warning = FALSE}
```  

```{r ncpg_setup, results = "hide", message = FALSE, warning = FALSE}
```  

## Aim:
To test the length of time taken to generate surrogate variables (SVs) using various different parameters and compare the SVs generated

## Methods:

### Data
Used the 450k data from ALSPAC mothers (timepoint = FOM, n = `r max(params$n_sample)`). This is DNA methylation measured in whole blood samples. All CpGs were used for analysis. 

Phenotype data was simulated using the rnorm() function in R.

### Analysis
__Parameters tested:__

* SVA package - sva and smartsva
* Number of CpGs - increasing from 20,000 to 300,000 by increments of 20,000 + the full set of CpGs (`r max(params$n_cpg)`)
	+ And whether subsetting the CpGs to the most variable CpGs or a random set works best 
* Number of SVs - comparison of 5, 10, 15, 20 SVs
* Number of samples - increasing from 100 to 900 by increments of 100

__SVA package:__

Time taken to run the analyses was compared as were the SVs generated by assessing the Pearsons correlation between SVs and how much of the variance of each SV generated using the sva package was explained by the same SV generated using the smartsva package.

We set the number of iterations used by each package to be the same and kept the other parameters as their defaults. 
 
Where unspecified, smartsva was chosen to run analyses.

__Number of CpGs:__
Time taken to run the analyses and the SVs generated by subsets of CpGs were compared to the same factors when running the analyses using all CpGs on the 450k array. To compare the SVs we took each of the SVs generated using all CpGs on the 450k array and calculated the variance of each of these SVs explained by all the SVs generated using the subset of CpGs. i.e:

$$SVi \sim SV1' + SV2' + ... + SV20'$$

where _SVi_ is the ith SV generated using all CpGs from the 450k array. 

For the number of SVs and the number of samples we just assessed run time.

## Results

### Timings

```{r time_plot, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap =time_plot_cap}
```

```{r time_plot2, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = time_plot2_cap}
```

### Smart vs normal sva
```{r sva_vs_smart_sva_table, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = smart_v_normal_cap}
```
correlation = Pearson's Rho
adjusted r^2^ = The variance of the SV generated using the sva package explained by the the variance of the SV generated by the smartsva package.
### Effectiveness of subseting CpGs
```{r mv_vs_random, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = mv_vs_random_plot_cap}
```
Number of CpGs is set to 20,000

```{r ncpg_plot, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = ncpg_plot_cap}
```

### Summary of findings
* smartsva was on average `r comma(mean(sva_times / smsva_times))` times faster than sva
* There was no difference between the SVs generated using the different packages
* As number of samples increased and number of CpGs increased so did time taken to run SVA
* Little difference in time taken when using 5, 10, 15, or 20 SVs 
* SVA for binary variables was faster than continuous
* The variance explained by all SVs created using a subset of 20000 CpGs of each of the SVs created using all `r max(params$n_cpg)` CpGs was greater when using a random subset compared to the most variable 20000 CpGs
	+ Variance explained decreases as the generated SV number increases (More variance explained for SV1 compared to SV10)
* Using all 20 SVs generated using a random subset of 20000 CpGs we explained over 90% of variance for the first 17 SVs generated using all `r max(params$n_cpg)` CpGs and over 99% of variance for the first 8 SVs









