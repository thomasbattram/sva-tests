# Assessing the best practice for surrogate variable analysis in epigenome-wide association studies

```{r setoptions, eval = TRUE, echo = FALSE}
opts_chunk$set(echo = FALSE, 
            warning = FALSE, 
            message = FALSE, 
            cache = FALSE, 
            dpi = 300)
```

```{r call_source}
read_chunk("~/sva_tests/report/sva_report.R")
```

``` {r load_data, results = "hide", message = FALSE, warning = FALSE}
```

```{r timings_setup, results = "hide", message = FALSE, warning = FALSE}
```  

```{r ncpg_setup, results = "hide", message = FALSE, warning = FALSE}
```  

```{r nsv_setup, results = "hide", message = FALSE, warning = FALSE}
```  


## Aim:
To test the length of time taken to generate surrogate variables (SVs) using various different parameters, compare the SVs generated and find out how many SVs are needed to account for variation in typical covariates.

## Methods:

### Data
Used the 450k data from ALSPAC mothers (timepoint = FOM1, n = `r max(params$n_sample)`). This is DNA methylation measured in whole blood samples. All CpGs were used for analysis. 

Phenotype data was simulated using the rnorm() function in R or was clinic data taken from the FOM1 timepoint. Ten "independent" variables (-0.2 < r < 0.2) chosen. 

### Analysis
__Parameters tested:__

* SVA package - sva and smartsva
* Number of CpGs - increasing from 20,000 to 300,000 by increments of 20,000 + the full set of CpGs (`r max(params$n_cpg)`)
	+ And whether subsetting the CpGs to the most variable CpGs or a random set works best 
* Number of SVs - comparison of 5, 10, 15, 20 SVs
* Number of samples - increasing from 100 to 900 by increments of 100

__SVA package:__

Time taken to run the analyses was compared as were the SVs generated by assessing the Pearsons correlation between SVs and how much of the variance of each SV generated using the sva package was explained by the same SV generated using the smartsva package.

We set the number of iterations used by each package to be the same and kept the other parameters as their defaults. 
 
Where unspecified, smartsva was chosen to run analyses.

__Effectiveness of subsetting CpGs:__
Time taken to run the analyses and the SVs generated by subsets of CpGs were compared to the same factors when running the analyses using all CpGs on the 450k array. To compare the SVs we took each of the SVs generated using all CpGs on the 450k array and calculated the variance of each of these SVs explained by all the SVs generated using the subset of CpGs. i.e:

$$SVi \sim SV1' + SV2' + ... + SV20'$$

where _SVi_ is the ith SV generated using all CpGs from the 450k array. 

For the number of SVs and the number of samples we just assessed run time.

__Number of SVs required__
The variance explained of often used covariates in EWAS by SVs was examined. The covariates chosen were: cell proportions derived using the Housemann method, two batch variables (BCD_id and MSA4Plate_id), age, and the top 10 genomic PCs. 

Normally distributed, random continous and binary variables were used as well as 10 randomly selected, independent (-0.2 < r < 0.2) variables from the FOM1 timepoint.

Firstly, the number of SVs required was estimated using either the num.sv() function from the sva package, with the "leek" method and by using random matrix theory as suggested by the smartsva package. The highest number of SVs estimated from either method was used as the maximum number of SVs required. 

Then, these SVs were generated for each trait using all of the probes on the 450k.

Finally, the cumulative variance explained by SVs for each covariate was examined. 

## Results

### Timings

```{r time_plot, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap =time_plot_cap}
```

```{r time_plot2, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = time_plot2_cap}
```

### Smart vs normal sva

```{r sva_vs_smart_sva_table, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = smart_v_normal_cap}
```

correlation = Pearson's Rho
adjusted r^2^ = The variance of the SV generated using the sva package explained by the the variance of the SV generated by the smartsva package.

### Effectiveness of subseting CpGs

```{r mv_vs_random, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = mv_vs_random_plot_cap}
```

Number of CpGs is set to 20,000

```{r ncpg_plot, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = ncpg_plot_cap}
```

### Variance explained of covariates by SVs

```{r est_num_plot, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = est_num_plot_cap}
```

```{r covs_var_exp, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = covs_var_exp_cap}
```

Variance explained is cummulative, i.e. adjusted r2 at SV 10 on the plot is the variance explained by SVs 1-10.
rcont = normally distributed random continuous variable
glc = glucose

```{r nsv_summary, results = "asis", message = FALSE, echo = FALSE, warning = FALSE, fig.cap = nsv_summary_cap}
```

median_sv_95 = median number of SVs required to account for 95% of the variance of the total variance explained by all the SVs estimated
median_sv_max = median number of SVs estimated to be required across traits
These medians are split by whether the data is simulated or real 

### Summary of findings
* smartsva was on average `r comma(mean(sva_times / smsva_times))` times faster than sva
* There was no difference between the SVs generated using the different packages
* As number of samples increased and number of CpGs increased so did time taken to run SVA
* Little difference in time taken when using 5, 10, 15, or 20 SVs 
* SVA for binary variables was faster than continuous
* The variance explained by all SVs created using a subset of 20000 CpGs of each of the SVs created using all `r max(params$n_cpg)` CpGs was greater when using a random subset compared to the most variable 20000 CpGs
	+ Variance explained decreases as the generated SV number increases (More variance explained for SV1 compared to SV10)
* Using all 20 SVs generated using a random subset of 20000 CpGs we explained over 90% of variance for the first 17 SVs generated using all `r max(params$n_cpg)` CpGs and over 99% of variance for the first 8 SVs
* The num.sv() function with the "leek" method estimates far fewer SVs required than is estimated using random matrix theory
* Many SVs may be needed to explain a large proportion of some key covariates such as cell type and batch variables
* SVs explain very little of the variance of genomic PCs (in this sample)









